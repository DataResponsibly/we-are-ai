---
title: Exploring Bias 
---

## Exploring Bias 
_Suggested time: 30 min_

<br>

#### Watch "Bias in AI” (12 min)

<div class="embed-responsive embed-responsive-16by9">
  <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/Lt0rNZT7jew" allowfullscreen>
  </iframe></div>
  
[View this video on YouTube](https://www.youtube.com/watch?v=Lt0rNZT7jew)

**References:**
* MIT Technology Review, “Racism is poisoning online ad delivery, says Harvard professor”, February 4, 2013 ([link](https://www.technologyreview.com/2013/02/04/253879/racism-is-poisoning-online-ad-delivery-says-harvard-professor/))
* Wall Street Journal, “Are workplace personality tests fair?”, September 29, 2014 ([link](http://www.wsj.com/articles/are-workplace-personality-tests-fair-1412044257))
* The Guardian, “Women less likely to be shown ads for high-paid jobs on Google, study shows”, July 8, 2015 ([link](https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study))
* Reuters, “Amazon scraps secret AI recruiting tool that showed bias against women”, October 10, 2018 ([link](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G))

<br>

#### Group Discussion (18 min)
Once you’ve completed the video, gather the group or split into breakout sessions to discuss this real-world scenario shared in the video.

**Gender Disparity in Amazon Recruiting**

In late 2018, it was discovered that Amazon’s AI recruiting tool, originally designed to boost workforce diversity, had taught itself to prioritize male candidates. The system was trained on historical data, using performance indicators from candidates who were hired through traditional means.

* Where do you see potential for bias in the data used by Amazon’s resume screening AI? Consider how overrepresentation, underrepresentation, or other kinds of distortion might play a role in how this machine learned.
* What stakeholders are harmed by the biased decisions of this tool? 
* What stakeholders benefit from these decisions?

**Discussion: Racism in Online Ads**

In 2013, Latanya Sweeney, a computer science professor at Harvard, noticed that searching Google for African-American-sounding names was more likely to display ads suggestive of criminal records than searching for white-sounding names, regardless of whether or not the individual had a criminal record.

* What are some possible reasons that this is happening?
* To which stakeholders can these types of ads cause harm? 
* What stakeholders benefit when these ads are shown?
* Who should be responsible for mitigating the harms?

The (financial) benefit is to Google’s ad serving platform and to the advertiser, Instant Checkmate, because they get higher click-through rates when these ads are shown in response to African-American-sounding names. Part of the reason for this is that employers are more likely to believe the ads in the case of an African American applicant, and are therefore more likely to click. Google is in the best position to mitigate - they benefit the most, and they are holding all the cards in terms of access to information about how their ad targeting platform works (we can only guess).
