---
title: Evaluating Automated Decision Systems
---

# Evaluating Automated Decision Systems
_Suggested time: 35 min_

As we saw in the video, Automated Decision Systems aid or replace human decisions. The decisions these systems make take many forms: predicting, classifying, optimizing, identifying, recommending, scoring, and adjudicating. Depending on where and how these decisions are made, these systems can have an impact on our opportunities, safety, rights, and behaviors. 

<br>

### Research (15 min)

In this activity we explore a local NYC example of an ADS, the Administration for Children’s Services (ACS) Child Welfare Child Risk and Safety Assessments tool. This system is used by ACS to evaluate potential child neglect and abuse cases for risk of child death or injury. Data used by this system often comes from multiple sources, including human services and law enforcement agencies. The system is not designed to make the final decision on child placement, but rather to advise a case worker on whether a reported case of potential child abuse or neglect should be further investigated or reviewed. We will do some research on this system and then debate its purpose and impacts. 

In breakout groups of 3–4 people, take 10 minutes to do a basic search for information about ACS’s Child Welfare Child Risk and Safety Assessments, following these prompts: 

1. Locate up to three news articles and/or one academic study about the tool -- at least one source for the tool’s benefits and one criticism against it.
1. What did you find? Is there public testimony? What issues do proponents and critics of the system raise? What does ACS say about its goal in using the tool? What do the families say? 

<br>

### Evaluation (10 min)

Next, share your results with your breakout group. Together, take another 10 minutes to fill out the [values/stakeholder matrix](https://blog.dataiku.com/algorithmic-stakeholders-an-ethical-matrix-for-ai) below using examples from your search and discussion. Choose a member of the team to present the matrix to the full group in the upcoming discussion.

<center><img src="https://raw.githubusercontent.com/p2pu/ai-for-the-people/gh-pages/img/05-03-evaluation-matrix.png" alt="Evaluation Matrix" width="100%"/></center>

<br>

### Discussion (10 min)

Return to the full group and spend 10 minutes exploring all of the breakout groups’ matrices. 

Discuss:
1. What did you notice about the public debate about the tool (E.g., are they “smart” or “trustworthy”?) What arguments for and against the tool were the most persuasive to your group and why?
1. Do you think the tool is working to accomplish its goals for ACS; for children and families; for case workers?
1. What would you change? How would you approach conversations with technologists and decision-makers to convince them to improve the design and use of the tool? 
