---
title: Evaluating Automated Decision Systems
---

# Evaluating Automated Decision Systems
_Suggested time: 35 min_

As we saw in the video, “Automated Decision Systems” aid or replace human decisions. The decisions these systems make take many forms: predicting, classifying, optimizing, identifying, recommending, scoring, and judging. Depending on where and how these decisions are made, these systems can have an impact on our opportunities, safety, rights, and behaviors. 

<br>

### Research (15 min)

In this activity we explore a local NYC example of an ADS, the ACS’s Child Welfare Child Risk and Safety Assessments tool. This system is used by ACS to evaluate potential child neglect and abuse cases for risk of child death/injury. Data often comes from multiple sources, including human services and law enforcement agencies. They are not necessarily designed to give ultimate decisions on child placement, but to advise on whether a reported case of potential child abuse/neglect should be further investigated or reviewed. We will do some research on this system and then debate its purpose and impacts in the city. 

In breakout groups of 3–4 people, take 10 minutes to do a basic search for information about ACS’s Child Welfare Child Risk and Safety Assessments, following these prompts: 

1. Locate up to three news articles and/or one academic study about the tool -- at least one source for the tool’s benefits and one criticism against it.
1. What did you find? Is there public testimony? Generally, what issues do proponents and critics raise? What does ACS say about its goal in using the tool? What about families? What do you think?

<br>

### Evaluation (10 min)

Next, share your results with your group, and together, take another 10 minutes to fill out the [values/stakeholder matrix](https://blog.dataiku.com/algorithmic-stakeholders-an-ethical-matrix-for-ai) below using examples from your search and discussion. Choose a member of the team who will present the matrix to the group in the upcoming discussion.

<center><img src="https://raw.githubusercontent.com/p2pu/ai-for-the-people/gh-pages/img/05-03-evaluation-matrix.png" alt="Evaluation Matrix" width="100%"/></center>

<br>

### Discussion (10 min)

Return to the full group and spend 10 minutes exploring all of the teams' matrices. 

Discuss:
1. What did you notice about the public debate about the tools (ex: for example, are they “smart” or “trustworthy”? What arguments - pro/con - were the most persuasive to your group and why?
1. Do you think the system is working to accomplish its goals for ACS; for children and families; for case workers?
1. What would you change? How would you approach technologists and decision-makers to improve the use of the tool? 

